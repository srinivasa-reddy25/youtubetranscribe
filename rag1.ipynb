{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Environment Variables: {'COMMAND_MODE': 'unix2003', 'HOME': '/Users/srinivasareddymedam', 'HOMEBREW_CELLAR': '/opt/homebrew/Cellar', 'HOMEBREW_PREFIX': '/opt/homebrew', 'HOMEBREW_REPOSITORY': '/opt/homebrew', 'INFOPATH': '/opt/homebrew/share/info:/opt/homebrew/share/info:', 'LOGNAME': 'srinivasareddymedam', 'MallocNanoZone': '0', 'NVM_BIN': '/Users/srinivasareddymedam/.nvm/versions/node/v22.13.1/bin', 'NVM_CD_FLAGS': '-q', 'NVM_DIR': '/Users/srinivasareddymedam/.nvm', 'NVM_INC': '/Users/srinivasareddymedam/.nvm/versions/node/v22.13.1/include/node', 'OLDPWD': '/', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined', 'PATH': '/Users/srinivasareddymedam/Desktop/FirstRAG/.venv/bin:/Users/srinivasareddymedam/google-cloud-sdk/bin:/Users/srinivasareddymedam/google-cloud-sdk/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/Users/srinivasareddymedam/.local/bin:/Users/srinivasareddymedam/.nvm/versions/node/v22.13.1/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin', 'PWD': '/', 'SHELL': '/bin/zsh', 'SHLVL': '1', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.1UOoA4crx0/Listeners', 'TMPDIR': '/var/folders/mf/4cf872fd5855rk67fvh1y8qw0000gn/T/', 'USER': 'srinivasareddymedam', 'VSCODE_CODE_CACHE_PATH': '/Users/srinivasareddymedam/Library/Application Support/Code/CachedData/6609ac3d66f4eade5cf376d1cb76f13985724bcb', 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost', 'VSCODE_CWD': '/', 'VSCODE_ESM_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_IPC_HOOK': '/Users/srinivasareddymedam/Library/Application Support/Code/1.98-main.sock', 'VSCODE_NLS_CONFIG': '{\"userLocale\":\"en-us\",\"osLocale\":\"en-us\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/Applications/Visual Studio Code.app/Contents/Resources/app/out/nls.messages.json\",\"locale\":\"en-us\",\"availableLanguages\":{}}', 'VSCODE_PID': '47106', 'XPC_FLAGS': '0x0', 'XPC_SERVICE_NAME': '0', '_': '/Users/srinivasareddymedam/Desktop/FirstRAG/.venv/bin/python', '__CFBundleIdentifier': 'com.microsoft.VSCode', '__CF_USER_TEXT_ENCODING': '0x1F5:0x0:0x0', 'ELECTRON_RUN_AS_NODE': '1', 'PINECONE_API_KEY': 'pcsk_4W1WWE_4qp6gEcRjLX7E86C4poXKcjH8EmuhMVvNZnVKkiWvpRd7YbeKvWmRChTk3zwCvL', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'utf-8', 'VIRTUAL_ENV': '/Users/srinivasareddymedam/Desktop/FirstRAG/.venv', 'GOOGLE_API_KEY': 'AIzaSyDA1rwT2_qJN0lQGVAVfZ3jYJKiXmTMOj0', 'PS1': '(.venv) ', 'VIRTUAL_ENV_PROMPT': '.venv', 'LC_CTYPE': 'UTF-8', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHON_FROZEN_MODULES': 'on', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}\n",
      "AIzaSyDA1rwT2_qJN0lQGVAVfZ3jYJKiXmTMOj0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# print(\"Loaded Environment Variables:\", dict(os.environ))\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# print(GOOGLE_API_KEY)\n",
    "\n",
    "\n",
    "YOUTUBE_VIDEO=\"https://www.youtube.com/watch?v=cdiD-9MMpb0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model=\"gemini-1.5-pro\"\n",
    "llm=ChatGoogleGenerativeAI(model=model, google_api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Los Angeles Dodgers won the 2020 World Series, which was played during the COVID-19 pandemic.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-0568d81a-6862-44ae-8a49-80a6bd2f3308-0', usage_metadata={'input_tokens': 16, 'output_tokens': 26, 'total_tokens': 42, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What MLB team Won the world series during the COVID-19 pandamic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"what is 2+2?\")\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Los Angeles Dodgers won the 2020 World Series, which was played during the COVID-19 pandemic.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser=StrOutputParser()\n",
    "\n",
    "chain = llm | parser\n",
    "\n",
    "chain.invoke(\"What MLB team Won the world series during the COVID-19 pandamic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\n\\nAnswer the question based on the context below. If you cannot find the answer in the context,\\n just say \"I don\\'t know\". Don\\'t try to make up an answer.\\n\\n context: Mary\\'s sister is sussana.\\n\\n question: who is Mary\\'s sister\\'s ?\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "template=\"\"\"\n",
    "\n",
    "Answer the question based on the context below. If you cannot find the answer in the context,\n",
    " just say \"I don't know\". Don't try to make up an answer.\n",
    "\n",
    " context: {context}\n",
    "\n",
    " question: {question}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Mary's sister is sussana.\", question=\"who is Mary's sister's ?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Susanna'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= prompt | llm | parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"context\":\"Mary's sister is sussana.\", \n",
    "    \"question\":\"who is Mary's sister's ?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBINING CHAINS IT IS APART FROM THE FLOW \n",
    "\n",
    "we can combine different chains to create more complex workflows. for explample lets create a second chain that trans;ltes the result  from first chain into differenbt language \n",
    "\n",
    "![Alt Text](Screenshot 2025-03-11 at 23.09.25.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_prompt=ChatPromptTemplate.from_template(\n",
    "    \"translate {answer} to {language} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Hindi translation of \"One\" is **एक** (ek).'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translate_chain=(\n",
    "    {\"answer\":chain, \"language\":itemgetter(\"Language\")}\n",
    "    | translate_prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "translate_chain.invoke(\n",
    "    {\n",
    "    \"context\": \"Mary's sister is Susana. She doesn't have any more siblings.\",\n",
    "    \"question\": \"How many sisters does Mary have?\",\n",
    "    \"Language\": \"Hindi\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribing the youtube video \n",
    "\n",
    "the context we want to send to the model comes from a youtube video and transcribe it usning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "\n",
    "\n",
    "# Let's do this only if we haven't created the transcription file yet.\n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    youtube = YouTube(YOUTUBE_VIDEO)\n",
    "    audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "    # Let's load the base model. This is not the most accurate\n",
    "    # model but it's fast.\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file = audio.download(output_path=tmpdir)\n",
    "        transcription = whisper_model.transcribe(file, fp16=False)[\"text\"].strip()\n",
    "\n",
    "        with open(\"transcription.txt\", \"w\") as file:\n",
    "            file.write(transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
